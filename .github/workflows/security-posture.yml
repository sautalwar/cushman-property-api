# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECURITY POSTURE DASHBOARD
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# What this file does (plain English):
#
# This workflow is the "always-on security camera" for your API.
# It runs automatically every 15 minutes and on every code push.
# It does four things in sequence:
#
#   1. READS   â€” Asks GitHub Advanced Security API: "what have you already found?"
#   2. PROBES  â€” Makes real HTTP requests to the live API to find runtime issues
#   3. REPORTS â€” Formats all findings as SARIF and uploads to GitHub Security tab
#   4. ACTS    â€” Creates GitHub Issues for new findings so a human can approve fixes
#
# The result is a single "security posture" report visible in GitHub Actions
# AND in the Security tab â€” one source of truth for the entire engineering team.
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

name: "ğŸ” Security Posture Dashboard"

# â”€â”€â”€ SECTION A: WHEN DOES THIS RUN? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# This workflow runs in three situations:
#
#   schedule  â†’ Automatically every 15 minutes, 24/7, even with no code changes.
#               This is the "always watching" behaviour. No human needs to trigger it.
#
#   push      â†’ Every time a developer pushes code to main. Catches regressions
#               immediately â€” if a new commit introduces a vulnerability, this
#               workflow finds it within seconds of the push.
#
#   pull_request â†’ Every time a PR is opened. Blocks the merge if new vulns are found.
#
#   workflow_dispatch â†’ Manual trigger from the GitHub UI with options. Useful for
#                       running a full audit on demand during an incident review.
#
on:
  schedule:
    - cron: '*/15 * * * *'      # Every 15 minutes â€” the heartbeat of your security posture
  push:
    branches: [main]
  pull_request:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment to probe'
        type: choice
        default: 'staging'
        options: [staging, production, local]
      fail_on_high:
        description: 'Fail workflow if HIGH or CRITICAL vulnerabilities found?'
        type: boolean
        default: true

# â”€â”€â”€ SECTION B: PERMISSIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# GitHub Actions workflows run with a scoped token (GITHUB_TOKEN).
# By default it can only read. We need to explicitly grant the extra
# permissions this workflow needs:
#
#   security-events: write  â†’ Allows uploading SARIF results to the Security tab
#   issues: write           â†’ Allows creating GitHub Issues for new findings
#   contents: read          â†’ Allows reading the repo (checking out code)
#
# IMPORTANT: These are the MINIMUM permissions needed. The principle of least
# privilege â€” we only ask for what we actually use.
#
permissions:
  security-events: write
  issues: write
  contents: read

env:
  GITHUB_REPO: ${{ github.repository }}     # e.g. sautalwar/cushman-property-api
  API_URL:     ${{ vars.API_URL || 'http://localhost:3001' }}

jobs:
  security-posture:
    name: "Security Posture Assessment"
    runs-on: ubuntu-latest

    steps:
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 1: CHECKOUT
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: Downloads the code from the repository into the runner.
      # Why needed:   The SARIF generation step (Step 4) needs to reference
      #               actual file paths in the source code so GitHub can link
      #               findings to the correct line in the editor.
      - name: "ğŸ“¥ Checkout repository"
        uses: actions/checkout@v4

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 2: READ GHAS CODE SCANNING ALERTS
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: Calls the GitHub API to get every open code-scanning alert.
      #               Code scanning alerts are created by CodeQL â€” GitHub's
      #               semantic static analyser that reads your source code.
      #
      # Why this matters: Before we run our own probes, we want to know what
      #               GitHub already knows. This prevents duplicate issues and
      #               lets us build a COMBINED picture: static findings + runtime
      #               findings in one report.
      #
      # The API call: GET /repos/{owner}/{repo}/code-scanning/alerts
      #               Returns a JSON array of all open alerts with:
      #               - rule.id          â†’ which security rule triggered
      #               - rule.severity    â†’ critical / high / medium / low
      #               - most_recent_instance.location â†’ file + line number
      #               - html_url         â†’ direct link to the alert in GitHub
      #
      - name: "ğŸ“¡ Step 1 â€” Read GHAS Code Scanning Alerts"
        id: code_scanning
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Fetching code scanning alerts from GitHub Advanced Security..."

          ALERTS=$(gh api \
            "/repos/$GITHUB_REPO/code-scanning/alerts?state=open&per_page=100" \
            --jq '[.[] | {
              id: .number,
              rule: .rule.id,
              severity: .rule.severity,
              description: .rule.description,
              file: .most_recent_instance.location.path,
              line: .most_recent_instance.location.start_line,
              url: .html_url
            }]' 2>/dev/null || echo '[]')

          COUNT=$(echo "$ALERTS" | python3 -c "import sys,json; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")
          echo "code_scan_count=$COUNT" >> $GITHUB_OUTPUT
          echo "$ALERTS" > /tmp/code_scan_alerts.json
          echo "Found $COUNT open code scanning alerts"

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 3: READ SECRET SCANNING ALERTS
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: Asks GitHub if any secrets (API keys, passwords, tokens,
      #               connection strings) were accidentally committed to git.
      #
      # Why this matters: A leaked JWT_SECRET means an attacker can forge tokens.
      #               A leaked DATABASE_URL gives direct database access.
      #               Secret scanning catches these within seconds of a push â€”
      #               faster than any human code review.
      #
      # The API call: GET /repos/{owner}/{repo}/secret-scanning/alerts
      #               Returns: secret_type (e.g. "github_personal_access_token"),
      #               location (file + line), push_protection_bypassed (was the
      #               developer warned and pushed anyway?)
      #
      - name: "ğŸ”‘ Step 2 â€” Read Secret Scanning Alerts"
        id: secret_scanning
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Fetching secret scanning alerts..."

          SECRETS=$(gh api \
            "/repos/$GITHUB_REPO/secret-scanning/alerts?state=open&per_page=50" \
            --jq '[.[] | {
              id: .number,
              type: .secret_type_display_name,
              bypassed: .push_protection_bypassed,
              url: .html_url
            }]' 2>/dev/null || echo '[]')

          COUNT=$(echo "$SECRETS" | python3 -c "import sys,json; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")
          echo "secret_count=$COUNT" >> $GITHUB_OUTPUT
          echo "$SECRETS" > /tmp/secret_alerts.json
          echo "Found $COUNT open secret scanning alerts"

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 4: READ DEPENDABOT ALERTS
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: Checks every npm package in package.json against the
      #               GitHub Advisory Database â€” a continuously updated database
      #               of known CVEs (Common Vulnerabilities and Exposures).
      #
      # Why this matters: 80% of modern application code is open-source
      #               dependencies. A vulnerability in an npm package you use
      #               is just as dangerous as one in your own code.
      #               Example: CVE-2021-44228 (Log4Shell) â€” if you used log4j,
      #               Dependabot would have flagged it the day it was published.
      #
      # The API call: GET /repos/{owner}/{repo}/dependabot/alerts
      #               Returns: CVE ID, severity, package name, vulnerable version,
      #               patched version, and a direct advisory URL.
      #
      - name: "ğŸ“¦ Step 3 â€” Read Dependabot Vulnerability Alerts"
        id: dependabot
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "Fetching Dependabot alerts..."

          DEPS=$(gh api \
            "/repos/$GITHUB_REPO/dependabot/alerts?state=open&per_page=50" \
            --jq '[.[] | {
              id: .number,
              package: .dependency.package.name,
              severity: .security_vulnerability.severity,
              cve: .security_advisory.cve_id,
              summary: .security_advisory.summary,
              patched_version: .security_vulnerability.first_patched_version.identifier,
              url: .html_url
            }]' 2>/dev/null || echo '[]')

          COUNT=$(echo "$DEPS" | python3 -c "import sys,json; print(len(json.load(sys.stdin)))" 2>/dev/null || echo "0")
          echo "dep_count=$COUNT" >> $GITHUB_OUTPUT
          echo "$DEPS" > /tmp/dep_alerts.json
          echo "Found $COUNT open Dependabot alerts"

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 5: LIVE RUNTIME API PROBES
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: This is the step that makes this workflow unique compared
      #               to pure static analysis tools. It makes ACTUAL HTTP requests
      #               to the running API and tests whether each vulnerability
      #               exists at runtime â€” not just in the code.
      #
      # Why this matters: Static analysis (CodeQL) reads code but cannot know
      #               about runtime configuration â€” environment variables,
      #               middleware order, framework behaviour, or infrastructure
      #               settings. Runtime probes catch what static analysis misses.
      #
      # What each probe does:
      #   BOLA probe      â†’ Logs in as Bob, tries to read Alice's job. If HTTP 200
      #                     â†’ VULN-1 confirmed: no ownership check at runtime.
      #   Auth probe      â†’ Sends a token with exp set 1 hour ago. If HTTP 200
      #                     â†’ VULN-2 confirmed: ignoreExpiration is still true.
      #   Rate limit      â†’ Sends 25 requests rapidly. If no 429 returned
      #                     â†’ VULN-6 confirmed: no per-user throttle.
      #   SQL injection   â†’ Sends q=' OR 1=1 -- to /search. If row count spikes
      #                     â†’ VULN-8 confirmed: string concatenation in SQL.
      #
      - name: "ğŸ”¬ Step 4 â€” Live Runtime API Probes"
        id: probes
        run: |
          API="${API_URL:-http://localhost:3001}"
          echo '{"findings":[]}' > /tmp/runtime_findings.json

          python3 - <<'PYEOF'
import json, os, urllib.request, urllib.error, base64, time

api = os.environ.get('API_URL', 'http://localhost:3001')
findings = []

def http(method, path, body=None, headers=None):
    """Simple HTTP helper â€” avoids needing curl or requests library."""
    url = f"{api}{path}"
    data = json.dumps(body).encode() if body else None
    hdrs = {'Content-Type': 'application/json', **(headers or {})}
    try:
        req = urllib.request.Request(url, data=data, headers=hdrs, method=method)
        with urllib.request.urlopen(req, timeout=4) as r:
            return r.status, json.loads(r.read())
    except urllib.error.HTTPError as e:
        return e.code, {}
    except Exception:
        return 0, {}   # API unreachable in CI â€” skip probe

def login(email):
    status, body = http('POST', '/api/auth/login',
                         {'email': email, 'password': 'Password123!'})
    return body.get('data', {}).get('token', '') if status == 200 else ''

# â”€â”€ Probe 1: BOLA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Bob (different owner) tries to read Alice's job. Should get 403, not 200.
bob_token = login('bob@propowner.com')
if bob_token:
    status, body = http('GET', '/api/jobs/cccccccc-0000-0000-0000-000000000001',
                         headers={'Authorization': f'Bearer {bob_token}'})
    if status == 200:
        findings.append({
            'id': 'VULN-1-BOLA', 'severity': 'critical',
            'rule': 'API1:2023 â€” Broken Object Level Authorization',
            'file': 'api/src/services/JobService.ts', 'line': 12,
            'message': f"Bob accessed Alice's job (HTTP {status}). "
                       f"Job title: '{body.get('data',{}).get('title','N/A')}'. "
                       "No owner_id check in SQL query.",
            'fix': "Add 'AND owner_id = $2' to WHERE clause in getJobById()"
        })

# â”€â”€ Probe 2: Broken Auth â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Send a token with exp = 1 hour ago. Should get 401, not 200.
import struct
def make_expired_jwt():
    now = int(time.time())
    hdr = base64.urlsafe_b64encode(b'{"alg":"HS256","typ":"JWT"}').rstrip(b'=').decode()
    pay = base64.urlsafe_b64encode(json.dumps({
        'userId': '11111111-0000-0000-0000-000000000001',
        'role': 'admin', 'iat': now - 7200, 'exp': now - 3600
    }).encode()).rstrip(b'=').decode()
    return f"{hdr}.{pay}.invalidsig"

expired = make_expired_jwt()
status, _ = http('GET', '/api/jobs', headers={'Authorization': f'Bearer {expired}'})
if status == 200:
    findings.append({
        'id': 'VULN-2-AUTH', 'severity': 'critical',
        'rule': 'API2:2023 â€” Broken Authentication',
        'file': 'api/src/middleware/auth.ts', 'line': 18,
        'message': f"Expired JWT accepted (HTTP {status}). "
                   "ignoreExpiration: true allows tokens expired hours/days ago.",
        'fix': "Remove ignoreExpiration: true from jwt.verify() options"
    })

# â”€â”€ Probe 3: Rate Limit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Send 20 rapid requests. If none return 429, rate limiting is missing.
charlie_token = login('charlie@plumbing.com')
if charlie_token:
    got_429 = False
    for i in range(20):
        status, _ = http('POST', '/api/jobs/cccccccc-0000-0000-0000-000000000001/bids',
                          {'amount': 100 + i},
                          headers={'Authorization': f'Bearer {charlie_token}'})
        if status == 429:
            got_429 = True
            break
    if not got_429:
        findings.append({
            'id': 'VULN-6-RATELIMIT', 'severity': 'medium',
            'rule': 'API4:2023 â€” Unrestricted Resource Consumption',
            'file': 'api/src/routes/jobs.ts', 'line': 45,
            'message': "20 consecutive bid requests accepted without any 429 response. "
                       "No per-user rate limiter on POST /api/jobs/:id/bids.",
            'fix': "Add express-rate-limit with keyGenerator: (req) => req.user.userId"
        })

# â”€â”€ Probe 4: SQL Injection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Send injection payload to /search. If row count is abnormally high â†’ vulnerable.
alice_token = login('alice@propowner.com')
if alice_token:
    _, baseline = http('GET', '/api/properties?limit=5',
                        headers={'Authorization': f'Bearer {alice_token}'})
    safe_count = baseline.get('count', 0)
    try:
        import urllib.parse
        q = urllib.parse.quote("' OR 1=1 --")
        status, body = http('GET', f'/api/properties/search?q={q}',
                             headers={'Authorization': f'Bearer {alice_token}'})
        injected_count = body.get('count', 0)
        if isinstance(injected_count, int) and isinstance(safe_count, int):
            if injected_count > safe_count + 2:
                findings.append({
                    'id': 'VULN-8-SQLI', 'severity': 'critical',
                    'rule': 'API8:2023 â€” Security Misconfiguration (SQL Injection)',
                    'file': 'api/src/services/PropertyService.ts', 'line': 67,
                    'message': f"SQL injection returned {injected_count} rows vs safe baseline {safe_count}. "
                               "Payload: q=' OR 1=1 --",
                    'fix': "Replace string concat with parameterized: WHERE name ILIKE $1"
                })
    except Exception:
        pass

# Write results
with open('/tmp/runtime_findings.json', 'w') as f:
    json.dump({'findings': findings}, f, indent=2)

print(f"Runtime probes complete â€” {len(findings)} finding(s)")
for f in findings:
    print(f"  [{f['severity'].upper()}] {f['id']}: {f['message'][:80]}...")
PYEOF

          COUNT=$(python3 -c "import json; d=json.load(open('/tmp/runtime_findings.json')); print(len(d['findings']))")
          echo "runtime_count=$COUNT" >> $GITHUB_OUTPUT

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 6: GENERATE SARIF FILE
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: Converts our runtime probe findings into SARIF format.
      #
      # What is SARIF? Static Analysis Results Interchange Format â€” an open
      #               standard (JSON schema) for representing security tool output.
      #               GitHub's Security tab understands SARIF natively, so by
      #               converting our custom probe results to SARIF, they appear
      #               in the SAME place as CodeQL findings â€” one unified view.
      #
      # Why this is powerful: Without SARIF, our probe results only exist in
      #               the Actions log â€” engineers have to dig through job logs.
      #               With SARIF, findings appear in:
      #                 â†’ Security > Code scanning (with file + line links)
      #                 â†’ Pull request checks (inline annotation on the diff)
      #                 â†’ Security Overview (org-wide aggregation)
      #               This turns our custom scripts into a first-class GHAS tool.
      #
      - name: "ğŸ“„ Step 5 â€” Generate SARIF from Runtime Findings"
        run: |
          python3 - <<'PYEOF'
import json, time

with open('/tmp/runtime_findings.json') as f:
    data = json.load(f)

findings = data.get('findings', [])

# SARIF severity mapping
sev_map = {'critical': 'error', 'high': 'error', 'medium': 'warning', 'low': 'note'}

# Build SARIF 2.1.0 document
sarif = {
    "version": "2.1.0",
    "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
    "runs": [{
        "tool": {
            "driver": {
                "name": "PropTracker Runtime API Security Probe",
                "version": "1.0.0",
                "informationUri": "https://github.com/sautalwar/cushman-property-api",
                "rules": [
                    {
                        "id": f["id"],
                        "name": f["id"].replace("-", ""),
                        "shortDescription": {"text": f["rule"]},
                        "fullDescription": {"text": f["message"]},
                        "helpUri": "https://owasp.org/API-Security/",
                        "properties": {"security-severity": "9.0" if f["severity"] == "critical" else "7.0" if f["severity"] == "high" else "5.0"}
                    }
                    for f in findings
                ]
            }
        },
        "results": [
            {
                "ruleId": f["id"],
                "level": sev_map.get(f["severity"], "warning"),
                "message": {"text": f"{f['message']} Fix: {f['fix']}"},
                "locations": [{
                    "physicalLocation": {
                        "artifactLocation": {"uri": f["file"], "uriBaseId": "%SRCROOT%"},
                        "region": {"startLine": f["line"]}
                    }
                }]
            }
            for f in findings
        ],
        "automationDetails": {"id": f"runtime-probe/{int(time.time())}"}
    }]
}

with open('/tmp/results.sarif', 'w') as f:
    json.dump(sarif, f, indent=2)

print(f"SARIF generated with {len(findings)} result(s)")
PYEOF

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 7: UPLOAD SARIF TO GITHUB SECURITY TAB
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: Sends the SARIF file to GitHub using the official
      #               CodeQL upload action. GitHub then processes it and makes
      #               each finding visible in the Security > Code Scanning tab,
      #               with direct links to the affected file and line number.
      #
      # Why use the action instead of the API directly?
      #               The action handles: gzip compression, base64 encoding,
      #               chunked upload for large files, retry on failure, and
      #               correctly sets the commit SHA so findings are pinned to
      #               the right version of the code.
      #
      - name: "â¬†ï¸  Step 6 â€” Upload SARIF to GitHub Security"
        uses: github/codeql-action/upload-sarif@v3
        if: always()   # Upload even if probes found issues (we WANT them in Security tab)
        with:
          sarif_file: /tmp/results.sarif
          category: runtime-api-probe   # Groups these findings separately from CodeQL

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 8: CREATE GITHUB ISSUES FOR NEW FINDINGS
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: For every runtime finding, checks if a GitHub Issue with
      #               that vulnerability ID is already open. If not, creates one.
      #               The issue includes: evidence, AI recommendation, and
      #               two label options (apply-fix / risk-accepted) so a human
      #               can decide whether to apply the Copilot-generated fix.
      #
      # Why check before creating? Deduplication. If the vulnerability exists
      #               in every run for 2 weeks, we don't want 1,344 duplicate issues.
      #               We create ONE issue and it stays open until the fix is merged.
      #
      - name: "ğŸš¨ Step 7 â€” Create GitHub Issues for New Findings"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 - <<'PYEOF'
import json, os, subprocess

with open('/tmp/runtime_findings.json') as f:
    data = json.load(f)

repo = os.environ.get('GITHUB_REPO', 'sautalwar/cushman-property-api')
icons = {'critical': 'ğŸ”´', 'high': 'ğŸŸ ', 'medium': 'ğŸŸ¡', 'low': 'ğŸ”µ'}

for finding in data.get('findings', []):
    vuln_id = finding['id']
    sev     = finding['severity']
    icon    = icons.get(sev, 'âš ï¸')

    # Check if an open issue for this vuln already exists
    existing = subprocess.run(
        ['gh', 'issue', 'list', '--repo', repo,
         '--label', f'vuln:{vuln_id}', '--state', 'open', '--json', 'number'],
        capture_output=True, text=True
    )
    if existing.stdout.strip() not in ('', '[]', 'null'):
        print(f"Issue already open for {vuln_id} â€” skipping")
        continue

    body = f"""## {icon} Runtime Security Finding: `{vuln_id}`

**Severity:** `{sev.upper()}`
**OWASP Category:** {finding['rule']}
**Affected file:** `{finding['file']}` (line {finding['line']})

---

### ğŸ”¬ What was detected

{finding['message']}

---

### ğŸ¤– AI-Recommended Fix (Copilot)

```typescript
// {finding['fix']}
```

---

### âœ… How to respond

This issue was created automatically by the Security Posture workflow.
Choose one of the following actions:

| Action | How | Result |
|--------|-----|--------|
| **Apply the fix** | Add label `apply-fix` | Copilot opens a PR with the patch |
| **Accept the risk** | Add label `risk-accepted` | Issue closed, finding suppressed |
| **Investigate** | Leave open | Stays in security backlog |

---
*Auto-generated by Security Posture Dashboard Â· Run [{os.environ.get('GITHUB_RUN_ID','')}](https://github.com/{repo}/actions/runs/{os.environ.get('GITHUB_RUN_ID','')})*
"""

    result = subprocess.run(
        ['gh', 'issue', 'create', '--repo', repo,
         '--title', f"{icon} Security Finding: {vuln_id} â€” {finding['rule'][:60]}",
         '--body', body,
         '--label', 'security,ai-recommendation,' + f'vuln:{vuln_id},{sev}'],
        capture_output=True, text=True
    )
    if result.returncode == 0:
        print(f"Created issue for {vuln_id}: {result.stdout.strip()}")
    else:
        print(f"Could not create issue for {vuln_id}: {result.stderr[:200]}")
PYEOF

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 9: WRITE SECURITY POSTURE DASHBOARD TO STEP SUMMARY
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: Generates a rich markdown report and writes it to
      #               GITHUB_STEP_SUMMARY â€” a special GitHub variable that
      #               renders markdown in the Actions run summary page.
      #
      # The report combines ALL four data sources into one view:
      #   - GHAS Code Scanning alert count
      #   - Secret Scanning alert count
      #   - Dependabot CVE count
      #   - Runtime probe findings with severity breakdown
      #   - Overall risk score (weighted by severity)
      #   - Links to open issues for remediation
      #
      - name: "ğŸ“Š Step 8 â€” Write Security Posture Dashboard"
        env:
          CODE_SCAN_COUNT: ${{ steps.code_scanning.outputs.code_scan_count }}
          SECRET_COUNT:    ${{ steps.secret_scanning.outputs.secret_count }}
          DEP_COUNT:       ${{ steps.dependabot.outputs.dep_count }}
          RUNTIME_COUNT:   ${{ steps.probes.outputs.runtime_count }}
          GH_TOKEN:        ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 - <<'PYEOF'
import json, os, datetime

repo = os.environ.get('GITHUB_REPO', 'sautalwar/cushman-property-api')
code_count    = int(os.environ.get('CODE_SCAN_COUNT', 0))
secret_count  = int(os.environ.get('SECRET_COUNT', 0))
dep_count     = int(os.environ.get('DEP_COUNT', 0))
runtime_count = int(os.environ.get('RUNTIME_COUNT', 0))

with open('/tmp/runtime_findings.json') as f:
    runtime = json.load(f)

findings = runtime.get('findings', [])
critical = sum(1 for f in findings if f['severity'] == 'critical')
high     = sum(1 for f in findings if f['severity'] == 'high')
medium   = sum(1 for f in findings if f['severity'] == 'medium')

# Risk score: weighted sum (critical=10, high=6, medium=3, secret=15, dep=4)
risk_score = (critical * 10) + (high * 6) + (medium * 3) + (secret_count * 15) + (dep_count * 4) + (code_count * 5)
risk_label = "ğŸ”´ CRITICAL" if risk_score > 30 else "ğŸŸ  HIGH" if risk_score > 15 else "ğŸŸ¡ MEDIUM" if risk_score > 5 else "ğŸŸ¢ LOW"

now = datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')
run_id = os.environ.get('GITHUB_RUN_ID', '')

summary = f"""# ğŸ” Security Posture Dashboard
**Repository:** `{repo}` | **Scanned:** {now} | **Overall Risk:** {risk_label} (score: {risk_score})

---

## ğŸ“Š Security Signal Summary

| Source | Open Findings | Severity | Action Required |
|--------|-------------|----------|----------------|
| ğŸ”¬ Runtime API Probes | **{runtime_count}** | Critical: {critical} Â· High: {high} Â· Medium: {medium} | {'ğŸš¨ Immediate' if critical > 0 else 'âš ï¸ Review'} |
| ğŸ” GHAS Code Scanning | **{code_count}** | See Security tab | {'ğŸš¨ Review now' if code_count > 0 else 'âœ… Clean'} |
| ğŸ”‘ Secret Scanning | **{secret_count}** | Critical (always) | {'ğŸš¨ ROTATE NOW' if secret_count > 0 else 'âœ… No secrets exposed'} |
| ğŸ“¦ Dependabot CVEs | **{dep_count}** | Mixed | {'âš ï¸ Upgrade deps' if dep_count > 0 else 'âœ… Dependencies clean'} |

---

## ğŸ”¬ Runtime Probe Findings
"""
if findings:
    for f in findings:
        icon = {'critical':'ğŸ”´','high':'ğŸŸ ','medium':'ğŸŸ¡'}.get(f['severity'],'âš ï¸')
        summary += f"\n### {icon} `{f['id']}` â€” {f['rule']}\n"
        summary += f"**File:** `{f['file']}` line {f['line']}\n\n"
        summary += f"**Evidence:** {f['message']}\n\n"
        summary += f"**Fix:** `{f['fix']}`\n\n"
        summary += "---\n"
else:
    summary += "\nâœ… **No runtime vulnerabilities detected in this scan.**\n\n---\n"

summary += f"""
## ğŸ”— Quick Links

- [Security Overview](https://github.com/{repo}/security) â€” All GHAS findings
- [Code Scanning Alerts](https://github.com/{repo}/security/code-scanning) â€” CodeQL results
- [Open Issues](https://github.com/{repo}/issues?q=label%3Aai-recommendation+is%3Aopen) â€” AI recommendations awaiting approval
- [Actions Run](https://github.com/{repo}/actions/runs/{run_id}) â€” This workflow run

---
*Security Posture Dashboard Â· Generated automatically by GitHub Actions Â· {now}*
"""

with open(os.environ.get('GITHUB_STEP_SUMMARY', '/tmp/summary.md'), 'w') as f:
    f.write(summary)
print("Security posture dashboard written to Step Summary")
PYEOF

      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # STEP 10: FAIL THE WORKFLOW IF CRITICAL/HIGH FINDINGS EXIST
      # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      # What it does: If this workflow is running on a pull_request AND the
      #               fail_on_high input is true (default), fails the check
      #               so the PR cannot be merged until vulnerabilities are resolved.
      #
      # Why fail? This is the "enforcement gate". Without it, security findings
      #               are informational only. By failing the PR check, we make
      #               security non-negotiable â€” a developer cannot ship vulnerable
      #               code without an explicit override from an admin.
      #
      - name: "ğŸš¦ Step 9 â€” Enforce: Fail on Critical or High Findings"
        if: github.event_name == 'pull_request' || inputs.fail_on_high == true
        run: |
          COUNT="${{ steps.probes.outputs.runtime_count }}"
          if [ "$COUNT" -gt "0" ] && [ "${{ inputs.fail_on_high }}" != "false" ]; then
            echo "::error::Security Posture Check FAILED â€” $COUNT runtime vulnerability/vulnerabilities detected."
            echo "::error::Review the Security Posture Dashboard in the Actions summary and apply AI recommendations."
            exit 1
          fi
          echo "âœ… Security posture check passed â€” no blocking findings."
